{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lending-Club-Loan-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lending Club Loan Data Analysis and Modeling\n",
    "Classification is one of two most common data science problems (another one is regression). For the supervised classification problem, imbalanced data are pretty common yet very challenging.\n",
    "\n",
    "For example, credit card fraud detection, disease classification, network intrusion and so on, are classification problem with imbalanced data.\n",
    "\n",
    "In this project, working with the Lending Club loan data, we hope to correctly predict whether or not on loan will be default using the history data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "For a traditional data science project, there are some common steps:\n",
    "\n",
    "Problem Statement\n",
    "Hypothesis and Goal\n",
    "\n",
    "Data Collection\n",
    "Can take $70\\%$ of the total time for some real-world projects\n",
    "\n",
    "Data Cleaning\n",
    "Business Sense\n",
    "Data Exploration\n",
    "And so on ......\n",
    "\n",
    "Feature Engineering and Data Visualization\n",
    "Categorical vs. Numerical features\n",
    "Missing Values\n",
    "Feature Transformation\n",
    "Feature Normalization\n",
    "And so on ......\n",
    "\n",
    "Machine Learning\n",
    "Logistic Regression\n",
    "Random Forest\n",
    "Boosting\n",
    "Neural Networks\n",
    "And so on ......\n",
    "\n",
    "Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, feature engineering and machine learning parts are usually iterative process. You may need to go through several rounds until you finish the whole modeling part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Problem Statement\n",
    "For companies like Lending Club, correctly predicting whether or not one loan will be default in the future is very important. In this project, using the historical data, more specifically, the Lending Club loan data from 2007 to 2018, we hope to build a machine learning model such that we can predict the chance of default for the future loans.\n",
    "\n",
    "As I will show later, this dataset is highly imbalanced and includes a lot of features, which makes this problem more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Collection\n",
    "There are several ways to download the dataset, for example, you can go to Lending Club's website, or you can go to Kaggle.\n",
    "\n",
    "I have downloaded the data from Lending Club's website.\n",
    "\n",
    "The original data is separated into different csv files. There are $145$ features originally. Based on my simple exploration and understanding, I finish the initial data cleaning part. More specifically:\n",
    "\n",
    "Choose the data from $2014$ until $2018$ to build model\n",
    "Remove features with large amount of missing values\n",
    "The full procedures are listed in the Jupyter Notebook [1. Data Collection and Cleaning]. After above two steps, there are $87$ features left, which are list below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Cleaning\n",
    "Based on business sense and initial exploration, $11$ irrelevant features are removed there are $77$ features left. After parsing the loan_status and removing the loans that are still in Current status, the dataset size is reduced from $1,642,574$ to $820,870$. Finally, the data from $2014$ until $2016$ are used as training set, and the data from $2017$ until $2018$ as the test set. So, finally there are $722,143$ (~$87.97\\%$) training data and $98727$ ($12.03\\%$) test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Feature Engineering and Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Machine Learning Modeling\n",
    "Imbalance Data\n",
    "Classification without re-sampling\n",
    "Under-sampling\n",
    "Over-sampling\n",
    "Random Over Sampling\n",
    "Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "Adaptive Synthetic Sampling (ADASYN)\n",
    "Anomaly Detection or Outlier Analysis\n",
    "\n",
    "#### Models\n",
    "\n",
    "Logistic Regression\n",
    "Random Forest\n",
    "Boosting\n",
    "Hierarchical Model\n",
    "And so on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection and Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('loan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
