{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Our Packages\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx=nlp(open('/home/pandit/DataScience/NLP/NLP_Projects/sentiment labelled sentences/readme.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\n",
       "Please cite the paper if you want to use it :)\n",
       "\n",
       "It contains sentences labelled with positive or negative sentiment, extracted from reviews of products, movies, and restaurants\n",
       "\n",
       "=======\n",
       "Format:\n",
       "=======\n",
       "sentence \\t score \\n\n",
       "\n",
       "\n",
       "=======\n",
       "Details:\n",
       "=======\n",
       "Score is either 1 (for positive) or 0 (for negative)\t\n",
       "The sentences come from three different websites/fields:\n",
       "\n",
       "imdb.com\n",
       "amazon.com\n",
       "yelp.com\n",
       "\n",
       "For each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. \n",
       "We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected.\n",
       "\n",
       "\n",
       "\n",
       "For the full datasets look:\n",
       "\n",
       "imdb: Maas et. al., 2011 'Learning word vectors for sentiment analysis'\n",
       "amazon: McAuley et. al., 2013 'Hidden factors and hidden topics: Understanding rating dimensions with review text'\n",
       "yelp: Yelp dataset challenge http://www.yelp.com/dataset_challenge"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punct, Stop\n",
    "#Nouns\n",
    "nouns=[token.text for token in docx if token.is_stop != True and token.is_punct !=True and token.pos_=='NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset',\n",
       " 'paper',\n",
       " 'sentences',\n",
       " 'sentiment',\n",
       " 'reviews',\n",
       " 'products',\n",
       " 'movies',\n",
       " 'Format',\n",
       " 'sentence',\n",
       " 'score',\n",
       " 'Details',\n",
       " 'Score',\n",
       " 'sentences',\n",
       " 'websites',\n",
       " 'fields',\n",
       " 'website',\n",
       " 'sentences',\n",
       " 'datasets',\n",
       " 'reviews',\n",
       " 'sentences',\n",
       " 'connotaton',\n",
       " 'goal',\n",
       " 'sentences',\n",
       " 'datasets',\n",
       " 'imdb',\n",
       " 'word',\n",
       " 'vectors',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'amazon',\n",
       " 'factors',\n",
       " 'topics',\n",
       " 'rating',\n",
       " 'dimensions',\n",
       " 'review',\n",
       " 'text',\n",
       " 'yelp',\n",
       " 'dataset',\n",
       " 'challenge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq=Counter(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_nouns=word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sentences', 5), ('dataset', 2), ('sentiment', 2), ('reviews', 2), ('datasets', 2), ('paper', 1), ('products', 1), ('movies', 1), ('Format', 1), ('sentence', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(common_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common verbs\n",
    "* Some stops words can also be verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### remove Punct,Stop\n",
    "verbs=[token.text for token in docx if token.is_punct !=True and token.pos_=='VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('was', 2), ('selected', 2), ('created', 1), ('using', 1), ('cite', 1), ('want', 1), ('use', 1), ('contains', 1), ('labelled', 1), ('extracted', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(verbs).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
